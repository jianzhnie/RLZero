# RLZero

A clean and easy implementation of MuZero, AlphaZero and Self-Play reinforcement learning algorithms for any game.

## References

### Unified Toolkits

- https://github.com/datamllab/rlcard
- https://github.com/google-deepmind/open_spiel
- https://github.com/sotetsuk/pgx.git
- https://github.com/Unity-Technologies/ml-agents

### AlpahZero

- https://github.com/suragnair/alpha-zero-general
- https://github.com/geochri/AlphaZero_Chess
- https://github.com/junxiaosong/AlphaZero_Gomoku
- https://github.com/lowrollr/turbozero
- https://github.com/dylandjian/SuperGo

### MuZero

- https://github.com/werner-duvaud/muzero-general
- https://github.com/koulanurag/muzero-pytorch
- https://github.com/YeWR/EfficientZero.git

### DouZero

- https://github.com/kwai/DouZero.git

### Blog

- https://medium.com/@bentou.pub/

- https://github.com/BentouAI/AlphaZero-Chain-Reaction

- https://medium.com/applied-data-science/alphago-zero-explained-in-one-diagram-365f5abf67e0

- https://bbs.huaweicloud.com/blogs/384922

- [How to Build Your Own MuZero Using Python (Part 1/3)](https://medium.com/applied-data-science/how-to-build-your-own-muzero-in-python-f77d5718061a)

- [How to Build Your Own MuZero Using Python (Part 2/3)](https://medium.com/applied-data-science/how-to-build-your-own-deepmind-muzero-in-python-part-2-3-f99dad7a7ad)

- [How to Build Your Own MuZero Using Python (Part 3/3)](https://medium.com/applied-data-science/how-to-build-your-own-deepmind-muzero-in-python-part-3-3-ccea6b03538b)

- [使用AlphaZero算法打造属于你自己的象棋AI!](https://aistudio.baidu.com/projectdetail/4215743?channelType=0&channel=0)

- [用飞桨框架2.0造一个会下五子棋的AI模型](https://aistudio.baidu.com/projectdetail/1403398?channelType=0&channel=0)

- [AlphaZero实现Connect4游戏](https://aistudio.baidu.com/projectdetail/2253753?channelType=0&channel=0)

- [极简MuZero算法实践——Paddle2.0版本](https://aistudio.baidu.com/projectdetail/1448859?channelType=0&channel=0)
